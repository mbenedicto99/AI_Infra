# PrevisÃ£o de Demanda & Capacidade na AWS com OpenTelemetry e IA

> Projeto de referÃªncia (POC â†’ Prod) para prever **demanda** (RPS, filas, trÃ¡fego) e **capacidade** (CPU/Mem/GPU, pods, nÃ³s, ASG) usando **OpenTelemetry**, **AWS** e modelos de IA (Prophet, DeepAR, TFT, N-BEATS). Inclui coleta de telemetria, data lake histÃ³rico, MLOps com SageMaker, e acionamento automÃ¡tico de polÃ­ticas de capacidade (Auto Scaling/HPA) respeitando SLOs.

---

## âœ¨ Objetivos
- **Prever demanda** por serviÃ§o, regiÃ£o e recurso (horizonte: 15minâ€“7 dias).
- Traduzir previsÃ£o em **polÃ­ticas de capacidade** (min/max/step scaling, scheduled actions, HPA targets).
- **Reduzir custo** (rightsizing, evitar over/under-provisioning) mantendo **SLO/SLI**.
- Prover **governanÃ§a**: versionamento de dados/modelos, auditoria de decisÃµes e observabilidade do pipeline.

## ðŸ—ï¸ Arquitetura (alto nÃ­vel)

```mermaid
flowchart LR
  subgraph Runtime & Telemetry
    A[AplicaÃ§Ãµes em EKS/EC2/Fargate]-->B[OpenTelemetry Collector (ADOT)]
    B-- Prometheus Remote Write -->C[Amazon Managed Prometheus (AMP)]
    B-- Traces -->D[AWS X-Ray]
    B-- EMF Metrics -->E[Amazon CloudWatch]
    A-- Logs -->F[CloudWatch Logs]
  end

  subgraph Data Lake & Analytics
    E-- Metric Streams -->G[Kinesis Firehose]
    F-- Subscription ->G
    G-->H[(Amazon S3 Data Lake)]
    H<-->I[AWS Glue Data Catalog]
    I-->J[Athena/EMR/Spark]
  end

  subgraph MLOps & Forecast
    J-->K[SageMaker Processing/Training]
    K-->L[Model Registry]
    L-->M[SageMaker Endpoint (Online)]
    L-->N[SageMaker Batch Transform]
    O[EventBridge Scheduler]-->K
    O-->P[Lambda - OrquestraÃ§Ã£o de AÃ§Ãµes]
  end

  subgraph Capacity Actions
    M-- PrevisÃ£o (curto prazo) -->P
    N-- PrevisÃ£o (janela diÃ¡ria) -->P
    P-->Q[AWS Auto Scaling (ASG/ECS)]
    P-->R[EKS HPA/VPA via Custom Metrics]
    P-->S[Reserved/Spot Planner (FinOps)]
  end

  C-->T[Grafana (AMG)]
  E-->T
  H-->T
```

**Notas-chave**
- **Coleta**: ADOT (AWS Distro for OpenTelemetry) para mÃ©tricas (AMP/CloudWatch), traces (X-Ray) e logs (CloudWatch).
- **HistÃ³rico**: CloudWatch **Metric Streams** + Logs â†’ Firehose â†’ **S3** (Parquet/partitionado) â†’ **Athena**.
- **Modelagem**: **SageMaker** com bibliotecas `GluonTS/Darts/Prophet`. Model Monitor para drift.
- **AÃ§Ã£o**: **Lambda** converte previsÃµes em aÃ§Ãµes (ASG scheduled scaling, HPA target updates) via **EventBridge**.

---

## âœ… Casos de uso prioritÃ¡rios
- **Autoscaling preditivo** de web/API (RPS/latÃªncia â†’ pods/nodes/ASG).
- **Planejamento de janelas**: madrugada, almoÃ§o, campanhas, feriados (BR).
- **Rightsizing**: limites de CPU/Mem/GPU por workload.
- **Custo**: evitar picos on-demand, sugerir Spot/RI conforme sazonalidade.

## ðŸ“¥ Fontes de dados mÃ­nimas
- **MÃ©tricas**: `http_requests_total`, `latency_ms`, `queue_depth`, `cpu_usage`, `memory_working_set`, `gpu_utilization`.
- **DimensÃµes** (labels): `service`, `env`, `region`, `pod/node`, `version` (commit/deploy).
- **Eventos**: deploys/feature-flags/reindex/batch em **EventBridge** (calendÃ¡rio de mudanÃ§as).
- **CalendÃ¡rio**: feriados nacionais/estaduais (BR) + eventos de negÃ³cio.
- **(Opcional)**: **CUR/Cost Explorer** para correlaÃ§Ã£o demanda â†” custo (FinOps).

---

## ðŸ§  Modelos de IA (recomendados por horizonte/uso)
- **Baselines** (sempre incluir): Sazonal diÃ¡ria/semana, Naive/Drift; para benchmarking e guard-rails.
- **Curto prazo (5â€“120 min)**: **TFT** (Temporal Fusion Transformer), **TCN/LSTM**, **N-BEATS** â†’ captura sazonalidade intradiÃ¡ria e choques.
- **Daily/Weekly**: **DeepAR** (probabilÃ­stico), **Prophet** (interpretaÃ§Ã£o forte, feriados).
- **ProbabilÃ­stico**: quantis Ï„âˆˆ{0.1,0.5,0.9} e **CRPS** para risco de under/over-provisioning.
- **Multivariado**: features exÃ³genas (deploys, temperatura, campanhas).

**MÃ©tricas**: **WAPE/MASE/SMAPE**, **RMSE**, **Pinball Loss** (quantis), **CRPS**.  
**ValidaÃ§Ã£o**: backtesting com **rolling-origin** (janelas deslizantes) e **gap** pÃ³s-treino.

---

## ðŸ“‚ Estrutura do repositÃ³rio
```
.
â”œâ”€â”€ infra/                 # Terraform (S3, Glue, Athena, AMP, AMG, Firehose, Roles, SM)
â”œâ”€â”€ otel/                  # Manifests ADOT p/ EKS e otel-collector.yaml
â”œâ”€â”€ data/                  # Esquemas, amostras Parquet/CSV (mock)
â”œâ”€â”€ notebooks/             # ExploraÃ§Ã£o, EDA, protÃ³tipos (Darts/GluonTS)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fe/                # Feature engineering (calendÃ¡rio, eventos, agregaÃ§Ãµes)
â”‚   â”œâ”€â”€ train/             # Scripts de treino (SageMaker Training Toolkit)
â”‚   â”œâ”€â”€ infer/             # Handlers (endpoint/batch), pÃ³s-processamento
â”‚   â”œâ”€â”€ actions/           # CÃ¡lculo de capacidade e chamadas AWS (ASG/HPA)
â”‚   â””â”€â”€ metrics/           # AvaliaÃ§Ã£o e monitoramento (WandB/Evidently/SM Monitor)
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ sm_pipelines.py    # DefiniÃ§Ã£o do pipeline (Processing->Train->Eval->Register->Deploy)
â”‚   â””â”€â”€ eventbridge.json   # Schedulers de retraining e batch forecasts
â”œâ”€â”€ tests/                 # Unit/e2e (pytest)
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

---

## ðŸ”§ Infraestrutura (Terraform â€“ visÃ£o)
- **S3 Data Lake** (camadas `raw/processed/predictions`, partition by `dt=YYYY-MM-DD`).
- **Glue**: Database + Crawlers para Parquet (mÃ©tricas/logs).
- **Athena**: Workgroup + Named Queries.
- **CloudWatch Metric Streams** â†’ **Firehose** â†’ S3 (Parquet).
- **CloudWatch Logs Subscription** â†’ Firehose â†’ S3.
- **AMP/AMG** para mÃ©tricas e dashboards.
- **SageMaker**: Roles, Model Registry, Endpoints (Serverless ou M5/G4dn), Monitor.
- **EventBridge/Lambda**: orquestraÃ§Ã£o de retraining/inferÃªncia/aÃ§Ãµes.
- **(Opcional)**: EKS + ADOT Addon; HPA via **custom.metrics.k8s.io** (adapter).

---

## ðŸ“¡ OpenTelemetry (ADOT) â€“ exemplo de Collector (EKS)
`otel/otel-collector.yaml` (trecho simplificado):
```yaml
receivers:
  otlp:
    protocols:
      grpc:
      http:

exporters:
  prometheusremotewrite:
    endpoint: https://aps-workspaces.${AWS_REGION}.amazonaws.com/workspaces/${AMP_WS_ID}/api/v1/remote_write
    auth:
      authenticator: sigv4auth
  awsxray: {}
  awsemf: {}  # mÃ©tricas em EMF -> CloudWatch
  logging:
    loglevel: info

extensions:
  sigv4auth: {}

service:
  extensions: [sigv4auth]
  pipelines:
    metrics:
      receivers: [otlp]
      exporters: [prometheusremotewrite, awsemf]
    traces:
      receivers: [otlp]
      exporters: [awsxray]
```

- **AMP**: dashboards em **Amazon Managed Grafana (AMG)** via Prometheus datasource.
- **CloudWatch**: habilita **Metric Streams â†’ Firehose** para materializar histÃ³rico em S3 (treino).

---

## ðŸ—ƒï¸ Esquema de dados no Data Lake (Parquet)
**Tabela `metrics_timeseries` (partitioned by `dt`)**
- `ts` (timestamp), `metric` (string), `value` (double)
- `service`, `env`, `region`, `pod`, `node`, `version` (strings)
- `window` (string; ex: `1m`, `5m`)
- `dt` (string; `YYYY-MM-DD`)

**Tabela `events_change`**
- `ts`, `service`, `event_type` (deploy/feature/campaign), `version`, `metadata` (json)

---

## ðŸ”¬ Feature Engineering (exemplos)
- **CalendÃ¡rio**: `dow`, `hour`, `is_weekend`, `is_holiday_BR`, `payday`, `campaign`.
- **Lagged/rolling**: `y(t-1â€¦t-96)`, mÃ©dias/medianas/quantis, **anomaly mask**.
- **ExÃ³genas**: fila, latÃªncia P95, **deploy_version**, **feature_flag**.
- **Business**: volume transacional/abandonos (se disponÃ­vel).

---

## ðŸ§ª AvaliaÃ§Ã£o & SLOs
- **SLO de previsÃ£o**: WAPE â‰¤ 15% intradiÃ¡rio; cobertura de intervalos [P10,P90] â‰¥ 80%.
- **SLO operacional**: â‰¤ 0.5% de violaÃ§Ãµes de **latÃªncia P95**/erro por under-provision.
- **A/B de polÃ­tica**: Causal Impact/Uplift para validar ganhos de custo/MTTR.

---

## ðŸ¤– Pipeline MLOps (SageMaker Pipelines)
1. **Processing** (Athena/Spark): materializa dataset por `service/env/region` (janelas e features).
2. **Training**: treina **TFT/DeepAR/N-BEATS/Prophet** + **baseline sazonal**.
3. **Evaluation**: backtesting (rolling-origin), calcula mÃ©tricas; gera relatÃ³rios.
4. **Register**: versiona no **Model Registry** com tags (`service=api-x`, `region=sa-east-1`).
5. **Deploy**: 
   - **Online**: Endpoint (Serverless ou provisionado).
   - **Batch**: Batch Transform diÃ¡rio para janelas longas.
6. **Monitor**: **Model Monitor** (drift), alarmes em **CloudWatch**.

---

## ðŸ–§ InferÃªncia â†’ AÃ§Ãµes de Capacidade
- **Lambda `capacity_planner`** (disparado por EventBridge ou S3 put):
  - Converte previsÃ£o probabilÃ­stica em **reservas**: usa `P90` para evitar under-provision.
  - **ASG/ECS**: cria/atualiza **Scheduled Actions** (ex.: 09:00â€“20:00 scale-out).
  - **EKS HPA**: ajusta target (RPS por pod / CPU target) via **K8s API** e **custom metrics**.
  - **FinOps**: sugere **Spot/RI** quando estabilidade > limiar (ex.: WAPE < 10% 30d).

---

## ðŸ§¾ Exemplo de Athena (agregaÃ§Ã£o 5-min, API `orders`)
```sql
CREATE OR REPLACE VIEW v_orders_rps_5m AS
SELECT
  date_trunc('minute', ts) AS ts_min,
  service,
  region,
  env,
  approx_percentile(value, 0.5) AS rps_p50,
  approx_percentile(value, 0.95) AS rps_p95
FROM metrics_timeseries
WHERE metric = 'http_requests_per_second'
  AND service = 'orders'
  AND env = 'prod'
  AND dt BETWEEN date_format(date_add('day', -30, current_date), '%Y-%m-%d') AND date_format(current_date, '%Y-%m-%d')
GROUP BY 1,2,3,4;
```

---

## ðŸ§‘â€ðŸ’» Treino (exemplo Python â€“ SageMaker + GluonTS/DeepAR)
```python
# src/train/train_deepar.py (resumo)
import json, os, pandas as pd, numpy as np
from gluonts.dataset.common import ListDataset
from gluonts.mx import Trainer
from gluonts.model.deepar import DeepAREstimator
from gluonts.evaluation.backtest import make_evaluation_predictions

FREQ = "5min"
PRED_LEN = 24  # 2h Ã  frente (5m * 24)

def load_series(path):
    df = pd.read_parquet(path)
    df = df.sort_values("ts")
    target = df["rps_p95"].astype(float).values
    start = pd.Timestamp(df["ts"].iloc[0], freq=FREQ)
    return ListDataset([{"start": start, "target": target}], freq=FREQ)

train_ds = load_series("/opt/ml/input/data/train/orders.parquet")
estimator = DeepAREstimator(freq=FREQ, prediction_length=PRED_LEN, trainer=Trainer(epochs=20))
predictor = estimator.train(train_ds)

# Salvar artefatos
predictor.serialize(Path("/opt/ml/model"))
```

---

## ðŸŸ¢ InferÃªncia online (handler â€“ SageMaker Endpoint)
```python
# src/infer/handler.py
import json, numpy as np, pandas as pd
from gluonts.model.predictor import Predictor
from pathlib import Path

model = None

def model_fn(model_dir):
    global model
    model = Predictor.deserialize(Path(model_dir))
    return model

def input_fn(request_body, request_content_type):
    payload = json.loads(request_body)
    # payload: {"recent_values": [...], "exog": {...}}
    return payload

def predict_fn(payload, model):
    pred = model.predict([{"start": pd.Timestamp.now(), "target": payload["recent_values"]}])
    forecast = next(pred)
    return {"p10": forecast.quantile(0.1).tolist(),
            "p50": forecast.quantile(0.5).tolist(),
            "p90": forecast.quantile(0.9).tolist()}

def output_fn(prediction, accept):
    return json.dumps(prediction), "application/json"
```

---

## ðŸ§® PolÃ­tica de capacidade (exemplo simplificado)
```python
# src/actions/capacity.py
def pods_needed(p90_rps, rps_per_pod, headroom=0.2):
    return int(np.ceil((p90_rps / rps_per_pod) * (1 + headroom)))

def asg_desired(pods, pods_per_node):
    return int(np.ceil(pods / pods_per_node))
```

---

## ðŸ”’ SeguranÃ§a & GovernanÃ§a
- **IAM mÃ­nimo necessÃ¡rio** (SageMaker, Firehose, Glue/Athena, CloudWatch, AMP, EKS).
- **Criptografia**: S3 (SSE-KMS), Athena spill, logs, endpoints (VPC + KMS).
- **Rede**: Endpoints VPC para S3/STS/SM; bloquear Internet em produÃ§Ã£o.
- **Auditoria**: CloudTrail + Athena Lake para trilhas de decisÃ£o (previsÃ£o â†’ aÃ§Ã£o).

---

## ðŸ’° Custos (estimativa POC)
- **AMP/AMG**: ingest/dashboards conforme cardinalidade (controle de labels!).
- **Firehose + S3 + Athena**: baixo custo por GB + consultas sob demanda.
- **SageMaker**: treino eventual (spot) + **Serverless Inference** p/ baixos picos.
- **X-Ray/CloudWatch**: dimensionar retenÃ§Ã£o; metric streams â‰ˆ US$ 0.01/1k mÃ©tricas + Firehose.

---

## â–¶ï¸ Como executar (POC)
1. **PrÃ©-requisitos**: `awscli`, `terraform`, `kubectl`, `helm`, Python 3.11.
2. **Provisionar**: `cd infra && terraform init && terraform apply` (defina `region`, `bucket_base`, `amp_ws`, `kms_key`).
3. **ADOT** (EKS): `helm repo add aws-observability https://aws-observability.github.io/helm-charts && helm install adot aws-observability/aws-otel-collector -f otel/otel-collector.yaml`.
4. **Metric Streams** â†’ Firehose â†’ S3 (Terraform jÃ¡ cria).
5. **Glue Crawlers** â†’ rodar e verificar tabelas `metrics_timeseries`/`events_change`.
6. **Athena** â†’ criar view `v_orders_rps_5m` e validar dados.
7. **SageMaker Pipeline**: `python pipelines/sm_pipelines.py --region sa-east-1 --service orders`.
8. **Endpoint**: ao terminar, obter o `EndpointName` e testar com `src/infer/client.py`.
9. **AÃ§Ãµes**: habilitar `EventBridge` + `Lambda capacity_planner` (variÃ¡veis: `service`, `rps_per_pod`).

---

## ðŸ§­ DecisÃµes de projeto (trade-offs)
- **AMP + CloudWatch** juntos: AMP para observabilidade em tempo real; CloudWatch para **Metric Streams** (S3 histÃ³rico).  
- **ProbabilÃ­stico por padrÃ£o**: minimiza **risco de under-provision** operacional.
- **P50 vs P90**: usar **P90** para produÃ§Ã£o; **P50** para eficiÃªncia sob SLO folgado.
- **Explainability**: Prophet para leitura de efeitos; TFT/N-BEATS para acurÃ¡cia.

---

## ðŸ‰ Riscos & AntipadrÃµes
- **Cardinalidade de labels** explode custos (AMP/CloudWatch/Glue). Normalize `service/env`.
- **Treinar com dados â€œsujosâ€ (incidentes)** sem mÃ¡scara â†’ viÃ©s.
- **Feedback loops**: autoscaling afeta mÃ©tricas; mantenha â€œhold-outâ€ e controle.
- **Falta de SLO**: IA nÃ£o substitui governanÃ§a de SLI/SLO e runbooks.

---

## ðŸ—ºï¸ Roadmap
- [ ] Adapter HPA (custom metrics) e polÃ­tica hÃ­brida (reactive + predictive).
- [ ] IntegraÃ§Ã£o **Cost & Usage Report** (CUR) para prever **custo** junto da **demanda**.
- [ ] ExperimentaÃ§Ã£o causal (Causal Impact) para provar ganho de polÃ­tica.
- [ ] Suporte a GPUs (inference servers) e jobs batch elÃ¡sticos (EMR/EKS/Karpenter).
- [ ] RL para tuning de polÃ­ticas de scaling sob SLO e custo (PPO).

---

## ðŸ“š ReferÃªncias rÃ¡pidas
- **ADOT/OTel**: semantic conventions (HTTP, DB, messaging).
- **SageMaker**: DeepAR/TFT/N-BEATS (via GluonTS/Darts), Model Monitor.
- **AWS**: CloudWatch **Metric Streams**, **AMP/AMG**, **EventBridge**, **Auto Scaling**, **EKS HPA**.

---

## ðŸ“ LicenÃ§a
MIT (ajuste conforme sua necessidade).
